{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 4: Feature Engineering\n",
    "\n",
    "## 🎯 Ziel\n",
    "Das Ziel des Feature Engineerings war, alle relevanten Informationen zu extrahieren, die für die Vorhersage des Anlasses (z. B. „Date Night“, „Ladys Night“) nützlich sind – ohne unnötiges Rauschen.\n",
    "\n",
    "## Encoding-Fokus & Beschreibung\n",
    "### Numerische Features:\n",
    "\n",
    "- duration_scaled: Dauer des Films (in Minuten), skaliert per MinMaxScaler, da die Werte stark variieren (z. B. Serien vs. Kurzfilme).\n",
    "- agerating_scaled: Altersfreigabe (z. B. PG-13 → 13), ebenfalls skaliert. Wichtig für Events wie „Family Night“ oder „Kids Night“.\n",
    "### Textuelle Features (via TF-IDF):\n",
    "\n",
    "- title und description wurden getrennt TF-IDF-vektorisiert, um semantische Begriffe wie „love“, „horror“, „christmas“ etc. zu erfassen.\n",
    "- Beispiel: Beschreibung mit „A romantic story set in winter“ → hoher Score für „romantic“ und „winter“, was z. B. „Date Night“ oder „Christmas“ begünstigt.\n",
    "### Genre-Features:\n",
    "\n",
    "Zwar encoded (One-Hot mit MultiLabelBinarizer), aber bewusst nicht für das finale Modell verwendet, da diese Information bereits stark in der Beschreibung reflektiert wird und zu Overfitting führen kann.\n",
    "\n",
    "## Feature Engineering für Zielvariable\n",
    "- Zielvariable: anlass_label – das erste Element aus der anlass_rule-Liste.\n",
    "- Die Label wurden vorher regelbasiert und mit TF-IDF-Keywords ergänzt – dadurch hohe Qualität und Konsistenz.\n",
    "- Wichtig für den Business-Case: Wer den Anlass kennt, kann zielgerichtete Empfehlungen geben – z. B. „Ladys Night“ → romantische Komödien mit weiblicher Hauptrolle.\n",
    "\n",
    "## Feature Importance\n",
    "Die Feature Importance wurde aus dem RandomForestClassifier extrahiert und aggregiert auf:\n",
    "\n",
    "- Beschreibung (TF-IDF): klar dominant\n",
    "- Titel: moderat wichtig\n",
    "- Dauer & Altersfreigabe: geringer, aber signifikant\n",
    "-> Das zeigt: Der Text (vor allem Beschreibung) ist der zentrale Prädiktor, was für Content-getriebene Empfehlungssysteme absolut plausibel ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 5: Modellierung\n",
    "\n",
    "- Modellwahl: RandomForestClassifier\n",
    "    - Modell: Random Forest Classifier\n",
    "\n",
    "- Warum Random Forest?\n",
    "    - Robust gegenüber Overfitting\n",
    "    - Kann mit vielen Features umgehen (z. B. Genres, Plattformen)\n",
    "    - Gibt Feature Importance zurück (nützlich für Business Insights)\n",
    "    - Funktioniert gut bei Multi-Class Classification – wie hier mit verschiedenen Anlässen\n",
    "\n",
    "\n",
    "## Grund für Wahl:\n",
    "- funktioniert gut mit hoher Dimensionalität (TF-IDF),\n",
    "- robust gegen Ausreißer & Skalenunterschiede,\n",
    "- liefert direkt Feature Importances (wichtig für Analyse),\n",
    "- keine starke Annahmen über die Datenverteilung nötig.\n",
    "\n",
    "## Bewertungsmetriken\n",
    "Genutzt wurde:\n",
    "- Accuracy: Gesamt-Trefferquote\n",
    "- Precision, Recall, F1-Score pro Klasse\n",
    "- Macro Average: wichtig bei ungleich verteilten Klassen (jede Klasse zählt gleich)\n",
    "→ Warum kein ROC-AUC?\n",
    "Da es sich um ein Multiclass-Problem mit mehr als 2 Klassen handelt, ist F1-Score + Macro Average deutlich interpretierbarer und nützlicher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion train_anlass_model(...) trainiert nur das Modell, sie berechnet (noch) keine fehlenden Anlässe.\n",
    "\n",
    "Was sie genau macht:\n",
    "📦 Feature-Auswahl: Wählt numerische Spalten aus (genre_*, platform_*, duration_scaled, agerating_scaled)\n",
    "🧹 Trainingsdaten filtern: Nur Zeilen, bei denen anlass_rule bereits vergeben ist (len(x) > 0)\n",
    "🎯 Zielspalte erzeugen: Das erste Element der anlass_rule-Liste wird zur Target-Variable anlass_label\n",
    "🧠 Modell trainieren: Ein RandomForestClassifier lernt auf diesen Daten, welcher Anlass zu einem Film passt\n",
    "📈 Modell evaluieren: Ausgabe eines classification_report, also Performance des Modells auf Testdaten\n",
    "🔁 Modell & Feature-Liste zurückgeben: Für spätere Anwendung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kapitel 6: Modeltraining & Hyperparameter\n",
    "\n",
    "## Split\n",
    "- train_test_split mit 80 % Training, 20 % Test\n",
    "- zufällig, aber durch random_state=42 reproduzierbar\n",
    "- wichtig: anlass_label wurde vorher extrahiert, nur Filme mit gültigem Label wurden für das Training verwendet\n",
    "\n",
    "## Hyperparameter\n",
    "Genutzt:\n",
    "- n_estimators=100 (Standard)\n",
    "- class_weight='balanced': automatisch ausgleichend bei ungleich verteilten Klassen\n",
    "- random_state=42: für Reproduzierbarkeit\n",
    "Noch kein GridSearch oder Optuna-Tuning → kann als nächster Schritt erfolgen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kapitel 7: Evaluation\n",
    "\n",
    "Die Bewertung des Modells erfolgte mit Fokus auf den **Macro F1-Score**, da das Datenset eine **unausgeglichene Klassenverteilung** aufweist. In solchen Fällen ist Accuracy als Metrik ungeeignet, da sie durch häufig vorkommende Klassen verzerrt werden kann. Auch Precision und Recall alleine liefern keine robuste Aussage über die Gesamtleistung.\n",
    "\n",
    "Der **Macro F1-Score** berechnet den F1-Wert **gleichgewichtet über alle Klassen hinweg**, unabhängig davon, wie oft eine Klasse im Datenset vorkommt. Dadurch wird sichergestellt, dass das Modell **alle Anlasse gleichermaßen** gut erkennen soll – nicht nur die häufigsten.\n",
    "\n",
    "Die Ergebnisse des trainierten Modells lauten wie folgt:\n",
    "\n",
    "- **Macro F1-Score:** `0.863`\n",
    "- **Weitere Klassenmetriken** (optional):\n",
    "  - Family Night: F1 = 0.93\n",
    "  - Educational Night: F1 = 0.89\n",
    "  - Date Night: F1 = 0.88\n",
    "  - Kids Night: F1 = 0.80\n",
    "  - Halloween Night: F1 = 0.78\n",
    "  - Christmas: F1 = 0.83\n",
    "\n",
    "Diese Werte zeigen, dass das Modell in der Lage ist, **auch seltener vorkommende Anlässe** zuverlässig vorherzusagen.\n",
    "\n",
    "**Fazit:** Die Wahl des Macro-F1-Scores als Zielmetrik ist in diesem Anwendungsfall gerechtfertigt und liefert eine faire Bewertung des Modells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dash_bootstrap_components  muss installiert werden wenn nicht vorhanden"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
