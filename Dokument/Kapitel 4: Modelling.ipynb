{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 4: Feature Engineering\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "Das Ziel des Feature Engineerings war, alle relevanten Informationen zu extrahieren, die fÃ¼r die Vorhersage des Anlasses (z.â€¯B. â€Date Nightâ€œ, â€Ladys Nightâ€œ) nÃ¼tzlich sind â€“ ohne unnÃ¶tiges Rauschen.\n",
    "\n",
    "## Encoding-Fokus & Beschreibung\n",
    "### Numerische Features:\n",
    "\n",
    "- duration_scaled: Dauer des Films (in Minuten), skaliert per MinMaxScaler, da die Werte stark variieren (z.â€¯B. Serien vs. Kurzfilme).\n",
    "- agerating_scaled: Altersfreigabe (z.â€¯B. PG-13 â†’ 13), ebenfalls skaliert. Wichtig fÃ¼r Events wie â€Family Nightâ€œ oder â€Kids Nightâ€œ.\n",
    "### Textuelle Features (via TF-IDF):\n",
    "\n",
    "- title und description wurden getrennt TF-IDF-vektorisiert, um semantische Begriffe wie â€loveâ€œ, â€horrorâ€œ, â€christmasâ€œ etc. zu erfassen.\n",
    "- Beispiel: Beschreibung mit â€A romantic story set in winterâ€œ â†’ hoher Score fÃ¼r â€romanticâ€œ und â€winterâ€œ, was z.â€¯B. â€Date Nightâ€œ oder â€Christmasâ€œ begÃ¼nstigt.\n",
    "### Genre-Features:\n",
    "\n",
    "Zwar encoded (One-Hot mit MultiLabelBinarizer), aber bewusst nicht fÃ¼r das finale Modell verwendet, da diese Information bereits stark in der Beschreibung reflektiert wird und zu Overfitting fÃ¼hren kann.\n",
    "\n",
    "## Feature Engineering fÃ¼r Zielvariable\n",
    "- Zielvariable: anlass_label â€“ das erste Element aus der anlass_rule-Liste.\n",
    "- Die Label wurden vorher regelbasiert und mit TF-IDF-Keywords ergÃ¤nzt â€“ dadurch hohe QualitÃ¤t und Konsistenz.\n",
    "- Wichtig fÃ¼r den Business-Case: Wer den Anlass kennt, kann zielgerichtete Empfehlungen geben â€“ z.â€¯B. â€Ladys Nightâ€œ â†’ romantische KomÃ¶dien mit weiblicher Hauptrolle.\n",
    "\n",
    "## Feature Importance\n",
    "Die Feature Importance wurde aus dem RandomForestClassifier extrahiert und aggregiert auf:\n",
    "\n",
    "- Beschreibung (TF-IDF): klar dominant\n",
    "- Titel: moderat wichtig\n",
    "- Dauer & Altersfreigabe: geringer, aber signifikant\n",
    "-> Das zeigt: Der Text (vor allem Beschreibung) ist der zentrale PrÃ¤diktor, was fÃ¼r Content-getriebene Empfehlungssysteme absolut plausibel ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 5: Modellierung\n",
    "\n",
    "- Modellwahl: RandomForestClassifier\n",
    "    - Modell: Random Forest Classifier\n",
    "\n",
    "- Warum Random Forest?\n",
    "    - Robust gegenÃ¼ber Overfitting\n",
    "    - Kann mit vielen Features umgehen (z.â€¯B. Genres, Plattformen)\n",
    "    - Gibt Feature Importance zurÃ¼ck (nÃ¼tzlich fÃ¼r Business Insights)\n",
    "    - Funktioniert gut bei Multi-Class Classification â€“ wie hier mit verschiedenen AnlÃ¤ssen\n",
    "\n",
    "\n",
    "## Grund fÃ¼r Wahl:\n",
    "- funktioniert gut mit hoher DimensionalitÃ¤t (TF-IDF),\n",
    "- robust gegen AusreiÃŸer & Skalenunterschiede,\n",
    "- liefert direkt Feature Importances (wichtig fÃ¼r Analyse),\n",
    "- keine starke Annahmen Ã¼ber die Datenverteilung nÃ¶tig.\n",
    "\n",
    "## Bewertungsmetriken\n",
    "Genutzt wurde:\n",
    "- Accuracy: Gesamt-Trefferquote\n",
    "- Precision, Recall, F1-Score pro Klasse\n",
    "- Macro Average: wichtig bei ungleich verteilten Klassen (jede Klasse zÃ¤hlt gleich)\n",
    "â†’ Warum kein ROC-AUC?\n",
    "Da es sich um ein Multiclass-Problem mit mehr als 2 Klassen handelt, ist F1-Score + Macro Average deutlich interpretierbarer und nÃ¼tzlicher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion train_anlass_model(...) trainiert nur das Modell, sie berechnet (noch) keine fehlenden AnlÃ¤sse.\n",
    "\n",
    "Was sie genau macht:\n",
    "ğŸ“¦ Feature-Auswahl: WÃ¤hlt numerische Spalten aus (genre_*, platform_*, duration_scaled, agerating_scaled)\n",
    "ğŸ§¹ Trainingsdaten filtern: Nur Zeilen, bei denen anlass_rule bereits vergeben ist (len(x) > 0)\n",
    "ğŸ¯ Zielspalte erzeugen: Das erste Element der anlass_rule-Liste wird zur Target-Variable anlass_label\n",
    "ğŸ§  Modell trainieren: Ein RandomForestClassifier lernt auf diesen Daten, welcher Anlass zu einem Film passt\n",
    "ğŸ“ˆ Modell evaluieren: Ausgabe eines classification_report, also Performance des Modells auf Testdaten\n",
    "ğŸ” Modell & Feature-Liste zurÃ¼ckgeben: FÃ¼r spÃ¤tere Anwendung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kapitel 6: Modeltraining & Hyperparameter\n",
    "\n",
    "## Split\n",
    "- train_test_split mit 80â€¯% Training, 20â€¯% Test\n",
    "- zufÃ¤llig, aber durch random_state=42 reproduzierbar\n",
    "- wichtig: anlass_label wurde vorher extrahiert, nur Filme mit gÃ¼ltigem Label wurden fÃ¼r das Training verwendet\n",
    "\n",
    "## Hyperparameter\n",
    "Genutzt:\n",
    "- n_estimators=100 (Standard)\n",
    "- class_weight='balanced': automatisch ausgleichend bei ungleich verteilten Klassen\n",
    "- random_state=42: fÃ¼r Reproduzierbarkeit\n",
    "Noch kein GridSearch oder Optuna-Tuning â†’ kann als nÃ¤chster Schritt erfolgen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kapitel 7: Evaluation\n",
    "\n",
    "Die Bewertung des Modells erfolgte mit Fokus auf den **Macro F1-Score**, da das Datenset eine **unausgeglichene Klassenverteilung** aufweist. In solchen FÃ¤llen ist Accuracy als Metrik ungeeignet, da sie durch hÃ¤ufig vorkommende Klassen verzerrt werden kann. Auch Precision und Recall alleine liefern keine robuste Aussage Ã¼ber die Gesamtleistung.\n",
    "\n",
    "Der **Macro F1-Score** berechnet den F1-Wert **gleichgewichtet Ã¼ber alle Klassen hinweg**, unabhÃ¤ngig davon, wie oft eine Klasse im Datenset vorkommt. Dadurch wird sichergestellt, dass das Modell **alle Anlasse gleichermaÃŸen** gut erkennen soll â€“ nicht nur die hÃ¤ufigsten.\n",
    "\n",
    "Die Ergebnisse des trainierten Modells lauten wie folgt:\n",
    "\n",
    "- **Macro F1-Score:** `0.863`\n",
    "- **Weitere Klassenmetriken** (optional):\n",
    "  - Family Night: F1 = 0.93\n",
    "  - Educational Night: F1 = 0.89\n",
    "  - Date Night: F1 = 0.88\n",
    "  - Kids Night: F1 = 0.80\n",
    "  - Halloween Night: F1 = 0.78\n",
    "  - Christmas: F1 = 0.83\n",
    "\n",
    "Diese Werte zeigen, dass das Modell in der Lage ist, **auch seltener vorkommende AnlÃ¤sse** zuverlÃ¤ssig vorherzusagen.\n",
    "\n",
    "**Fazit:** Die Wahl des Macro-F1-Scores als Zielmetrik ist in diesem Anwendungsfall gerechtfertigt und liefert eine faire Bewertung des Modells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dash_bootstrap_components  muss installiert werden wenn nicht vorhanden"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
